{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540cc229",
   "metadata": {},
   "source": [
    "# Dragon Real Estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cc0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d8fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"data.csv\", delimiter=\"\\t\", encoding=\"utf-8\") # read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15eb469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing.head() # it will show top 5 rows\n",
    "# housing.info() # check info about data - how many entries in column or is there any null value\n",
    "# housing['chas'] # it will show chas column ka data\n",
    "# housing['chas'].value_counts() # it will show chas me kon value kitne bar aa rha hai\n",
    "# housing.describe() # ye aapko har column ka [mean, std, min] etc, deta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13e7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open graph inline\n",
    "# %matplotlib inline\n",
    "\n",
    "# import\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# watch histogram of our housing data\n",
    "# The bins=50 parameter specifies the number of bins or intervals in the histogram. Increasing the number of bins provides more detailed information, while decreasing it gives a more generalized view. \n",
    "# The figsize=(20, 15) parameter sets the figure size of the histogram plot, where (20, 15) represents the width and height in inches.\n",
    "# housing.hist(bins=50, figsize=(20, 15))\n",
    "\n",
    "# show the graph - jupyter m auto chalta show function (na bhi likho to chelga)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dd40d3",
   "metadata": {},
   "source": [
    "# Train-Test Splitting Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42dc2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "\n",
    "# def split_train_test(data, test_ratio):\n",
    "#     np.random.seed(42) # 42 convention chla a rha hi bs - np.random.permutation() function bs ek bar hi permulatation krega or bar bar run hone par bhi first time wala jo permutation aaya tha wahi dega [isse hm test set wale data ko dekhne se bach jate h]\n",
    "#     shuffled_arr = np.random.permutation(len(data)) # ager 50 diya to 1 to 50 ye random array dega\n",
    "#     test_set_size = int(len(data) * test_ratio)\n",
    "#     test_indices_arr = shuffled_arr[0:test_set_size]\n",
    "#     train_indices_arr = shuffled_arr[test_set_size:]\n",
    "#     return data.iloc[train_indices_arr], data.iloc[test_indices_arr] # iloc[]: It is a pandas indexing operator that allows you to access data based on integer location.\n",
    "\n",
    "\n",
    "# train_set, test_set = split_train_test(housing, 0.2)\n",
    "\n",
    "# print(f\"Row in train set: {len(train_set)} \\nRows in test set: {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff17e1e8",
   "metadata": {},
   "source": [
    "# Train test Splitting using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08777942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# chas - ye total 506 h and [0 value 437 hai or 1 value 35 hai] - ho skta h hm train set m kebal 0 wale hi de de sare or 1 value de hi na paye to isse resolve krne ke liye ham stratifiedShuffleSplit krte h taki kuch ratio m ye test or train m jaye\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing['chas']):\n",
    "    strat_train_set = housing.loc[train_index] # loc[]: It is a pandas indexing operator that allows you to access data by label. It is used here to select specific rows based on the provided index label(s).\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "# strat_train_set['chas'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deae2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove medv column - because it is our label: ye prices hai room ke jise ham label bol skte hai\n",
    "housing = strat_train_set.drop('medv', axis=1);\n",
    "housingLabels = strat_train_set['medv'].copy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c97601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test splitting hone ke baad se ab test set ko bhul jao or work only on train set data\n",
    "housing_train_set = strat_train_set.copy()\n",
    "housing_train_set = housing_train_set.drop('medv', axis=1);\n",
    "# housing_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5a171",
   "metadata": {},
   "source": [
    "# Looking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "593c84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create correlation matrix\n",
    "# correlation value from [-1 to 1] -1 = negative correlation || 1 = positive correlation\n",
    "# eg: Salary increase [saving increase (1) and financial stress decrease(-1)]\n",
    "# corr_matrix = housing_train_set.corr()\n",
    "\n",
    "\n",
    "\n",
    "# medv ko base rakh kar baki column values ke sath correlations find krna\n",
    "# corr_matrix['medv'].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# har attributes ka each other ke sath correlation graph dekhna\n",
    "# from pandas.plotting import scatter_matrix\n",
    "# attributes = [\"medv\", \"rm\", \"zn\", \"lstat\"]\n",
    "# scatter_matrix(housing_train_set[attributes], figsize=(12, 8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2 columns ka correlation graph dekhna\n",
    "# alpha: kitna dark dekhna \n",
    "# housing_train_set.plot(kind=\"scatter\", x=\"rm\", y=\"medv\", alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98591e3",
   "metadata": {},
   "source": [
    "# Create Your own Attribute Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7770f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aap kudh ka new attribute bna do jo aapko ease de \n",
    "# eg: tax and rooms diya ho to : taxi per rooms attrubute bna do [tax/room]\n",
    "\n",
    "# housing_train_set['taxrm'] = housing_train_set['tax'] / housing_train_set['rm'];\n",
    "\n",
    "# housing['taxrm']\n",
    "# housing.plot(kind=\"scatter\", x=\"taxrm\", y=\"medv\", alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bed643",
   "metadata": {},
   "source": [
    "# handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f0c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three ways to handling null values\n",
    "# 1. remove whole particular row\n",
    "# newHousing = housing_train_set.dropna(subset=['rm']);\n",
    "# newHousing.shape\n",
    "\n",
    "# 2. remove whole particular column\n",
    "# newHousing = housing_train_set.drop('rm', axis=1);\n",
    "# newHousing.shape\n",
    "\n",
    "# 3. set the null value to some value (0, mean or median)\n",
    "# note: chehe input aaye chahe test or train set aaye = aapko yhi median value use krna h koi alag value mt le lena : is median ki value ko save kr le kahi\n",
    "# median = housing_train_set['rm'].median();\n",
    "# newHousing = housing_train_set['rm'].fillna(median)\n",
    "# newHousing.shape\n",
    "\n",
    "\n",
    "# ye automatic jo median aayega usse save krke rkega or null values ke sare row ka particular median lekar pure row m save kr dega [uper method 3 ka upgrade or best version h ye]\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(housing_train_set);\n",
    "\n",
    "x = imputer.transform(housing_train_set) # numpy array dega\n",
    "newHousing = pd.DataFrame(x, columns=housing_train_set.columns) # dataframe bnaya\n",
    "# newHousing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca2f3e",
   "metadata": {},
   "source": [
    "# Scikit-learn Design\n",
    "\n",
    "Here are some important objects in scikit-learn:\n",
    "\n",
    "Estimators:\n",
    "Estimators are objects in scikit-learn that perform learning on data. They are used to fit models to training data and make predictions on new, unseen data. Every algorithm in scikit-learn is represented by an estimator class. Estimators have a consistent API with two main methods:\n",
    "1.  fit(X, y) to train the model using the input features X and the target values y\n",
    "2.  predict(X_new) to make predictions on new data X_new. \n",
    "Estimators may also have additional methods for model evaluation, parameter tuning, and other functionalities specific to the algorithm they represent.\n",
    "Examples: RandomForestClassifier, LinearRegression, KMeans\n",
    "\n",
    "Transformers:\n",
    "Transformers are objects in scikit-learn that preprocess and transform data. They are used for tasks such as feature scaling, dimensionality reduction, feature extraction, and data cleaning. \n",
    "#Transformers have a fit(X) method to learn the transformation parameters from the input data X and a transform(X_new) method to apply the learned transformation to new data X_new. \n",
    "#Some transformers also provide a fit_transform(X) method that combines the fitting and transforming steps.\n",
    "#Examples: StandardScaler, PCA, OneHotEncoder\n",
    "\n",
    "Pipelines:\n",
    "Pipelines are a way to chain multiple transformers and estimators together into a single object. They are useful for creating a sequence of data processing steps followed by model training and prediction. Pipelines ensure that data flows seamlessly between the different steps, allowing for efficient and reproducible machine learning workflows. They simplify the process of applying the same data preprocessing steps to both the training and test data, and they enable easy deployment of the entire pipeline for real-world predictions.\n",
    "Example: Pipeline (combines transformers and an estimator into a single object)\n",
    "\n",
    "Model Evaluation Metrics:\n",
    "Scikit-learn provides a wide range of evaluation metrics to assess the performance of machine learning models. These metrics allow you to quantify the quality of predictions and make comparisons between different models. The available metrics depend on the type of problem, such as classification, regression, clustering, or ranking. These metrics help you evaluate the accuracy, precision, recall, F1 score, mean squared error, R-squared, and other performance aspects of your models.\n",
    "Examples: accuracy_score, mean_squared_error, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128dacd2",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## What is feature scaling:\n",
    "Feature scaling, also known as data normalization, is a technique used in machine learning to standardize the range of features or variables in a dataset. It aims to bring all features to a similar scale, eliminating the dominance of certain features due to their larger magnitudes or units.\n",
    "\n",
    "## Why use feature scaling:\n",
    "Consider a dataset that contains information about houses, including features such as area in square feet and number of bedrooms. Let's say the area feature values range from 500 to 5000 square feet, while the number of bedrooms feature values range from 1 to 5.\n",
    "\n",
    "Without feature scaling, the difference in scales between the two features can cause issues. For instance, a machine learning algorithm that uses a distance-based metric, like k-nearest neighbors, may be heavily influenced by the larger values of the area feature. This can result in the number of bedrooms feature having less impact on the predictions.\n",
    "\n",
    "By applying feature scaling, you can bring both features to a similar scale, allowing the algorithm to give equal importance to both features during training and prediction. This helps in avoiding biases towards features with larger magnitudes and can lead to more accurate models.\n",
    "\n",
    "## There are two common methods of feature scaling:\n",
    "\n",
    "### 1. Standardization (Z-score normalization):\n",
    "Standardization transforms the data so that it has a mean of 0 and a standard deviation of 1. It involves subtracting the mean value of the feature from each data point and then dividing it by the standard deviation. The resulting transformed feature will have a mean of 0 and a standard deviation of 1. Standardization preserves the shape of the distribution and is less affected by outliers.\n",
    "\n",
    "The formula for standardization is:\n",
    "#### X_scaled = (X - mean(X)) / std(X)\n",
    "\n",
    "##### Sklearn provide function called : StandardScalar\n",
    "\n",
    "\n",
    "\n",
    "### 2. Min-Max scaling:\n",
    "Min-Max scaling, also known as normalization, rescales the data to a specific range, typically between 0 and 1. It involves subtracting the minimum value of the feature from each data point and then dividing it by the difference between the maximum and minimum values. The resulting transformed feature will have values between 0 and 1. Min-Max scaling maintains the relative relationships between the data points and is sensitive to outliers.\n",
    "\n",
    "The formula for min-max scaling is:\n",
    "#### X_scaled = (X - min(X)) / (max(X) - min(X))\n",
    "\n",
    "##### Sklearn provide function called : MinMaxScalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d2da3",
   "metadata": {},
   "source": [
    "# Creating a Pipleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c9d0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04819</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>6.108</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.2203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>392.89</td>\n",
       "      <td>6.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01501</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>6.635</td>\n",
       "      <td>29.7</td>\n",
       "      <td>8.3440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>390.94</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.87141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.484</td>\n",
       "      <td>93.6</td>\n",
       "      <td>2.3053</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.21</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.18159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>6.376</td>\n",
       "      <td>54.3</td>\n",
       "      <td>4.5404</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>6.312</td>\n",
       "      <td>28.9</td>\n",
       "      <td>5.4159</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3.53501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>6.152</td>\n",
       "      <td>82.6</td>\n",
       "      <td>1.7455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>88.01</td>\n",
       "      <td>15.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>7.05042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.103</td>\n",
       "      <td>85.1</td>\n",
       "      <td>2.0218</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.52</td>\n",
       "      <td>23.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.08187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.445</td>\n",
       "      <td>7.820</td>\n",
       "      <td>36.9</td>\n",
       "      <td>3.4952</td>\n",
       "      <td>2.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>393.53</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>4.75237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.525</td>\n",
       "      <td>86.5</td>\n",
       "      <td>2.4358</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>50.92</td>\n",
       "      <td>18.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.04560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>5.888</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.1121</td>\n",
       "      <td>5.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>392.80</td>\n",
       "      <td>13.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis   rad    tax  \\\n",
       "0    0.04819  80.0   3.64   0.0  0.392  6.108  32.0  9.2203   1.0  315.0   \n",
       "1    0.01501  80.0   2.01   0.0  0.435  6.635  29.7  8.3440   4.0  280.0   \n",
       "2    4.87141   0.0  18.10   0.0  0.614  6.484  93.6  2.3053  24.0  666.0   \n",
       "3    0.18159   0.0   7.38   0.0  0.493  6.376  54.3  4.5404   5.0  287.0   \n",
       "4    0.30347   0.0   7.38   0.0  0.493  6.312  28.9  5.4159   5.0  287.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...   ...    ...   \n",
       "399  3.53501   0.0  19.58   1.0  0.871  6.152  82.6  1.7455   5.0  403.0   \n",
       "400  7.05042   0.0  18.10   0.0  0.614  6.103  85.1  2.0218  24.0  666.0   \n",
       "401  0.08187   0.0   2.89   0.0  0.445  7.820  36.9  3.4952   2.0  276.0   \n",
       "402  4.75237   0.0  18.10   0.0  0.713  6.525  86.5  2.4358  24.0  666.0   \n",
       "403  0.04560   0.0  13.89   1.0  0.550  5.888  56.0  3.1121   5.0  276.0   \n",
       "\n",
       "     ptratio       b  lstat  \n",
       "0       16.4  392.89   6.57  \n",
       "1       17.0  390.94   5.99  \n",
       "2       20.2  396.21  18.68  \n",
       "3       19.6  396.90   6.87  \n",
       "4       19.6  396.90   6.15  \n",
       "..       ...     ...    ...  \n",
       "399     14.7   88.01  15.02  \n",
       "400     20.2    2.52  23.29  \n",
       "401     18.0  393.53   3.57  \n",
       "402     20.2   50.92  18.13  \n",
       "403     16.4  392.80  13.51  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "my_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "newHousingNumpyArr = my_pipeline.fit_transform(newHousing)\n",
    "# newHousingNumpyArr.shape\n",
    "newHousing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770135fa",
   "metadata": {},
   "source": [
    "# Selecting a desired model for Dragon Real Estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad05180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.279, 25.401, 16.506, 23.526, 23.494])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# model = LinearRegression();\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# model = DecisionTreeRegressor()\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(newHousingNumpyArr, housingLabels)\n",
    "\n",
    "someData = newHousing.iloc[:5]\n",
    "someLabels = housingLabels.iloc[:5]\n",
    "\n",
    "prepared_data = my_pipeline.transform(someData)\n",
    "model.predict(prepared_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44852575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254    21.9\n",
       "348    24.5\n",
       "476    16.7\n",
       "321    23.1\n",
       "326    23.0\n",
       "Name: medv, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f31556",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9706fbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2421232978769499"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "housingPredictions = model.predict(newHousingNumpyArr)\n",
    "mse = mean_squared_error(housingLabels, housingPredictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335e0aa",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d48661e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.91456362, 2.7488174 , 4.47052355, 2.72922345, 3.4276394 ,\n",
       "       2.57153758, 4.62099457, 3.31734745, 3.37177549, 3.30152015])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# using K-Fold Cross Validation \n",
    "scores = cross_val_score(model, newHousingNumpyArr, housingLabels, scoring=\"neg_mean_squared_error\", cv=10); # cv means K\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e65b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [2.91456362 2.7488174  4.47052355 2.72922345 3.4276394  2.57153758\n",
      " 4.62099457 3.31734745 3.37177549 3.30152015]\n",
      "Mean:  3.3473942657897995\n",
      "Standard Deviation:  0.6650746914529427\n"
     ]
    }
   ],
   "source": [
    "def print_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard Deviation: \", scores.std())\n",
    "    \n",
    "print_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694e5b0",
   "metadata": {},
   "source": [
    "# Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55a7e42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DragonModel.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'DragonModel.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fde626",
   "metadata": {},
   "source": [
    "# Testing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f429a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.954004936804721"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = strat_test_set.drop('medv', axis=1)\n",
    "y_test = strat_test_set['medv'].copy()\n",
    "x_test_prepared = my_pipeline.transform(x_test)\n",
    "final_prediction = model.predict(x_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_prediction)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6c10d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
